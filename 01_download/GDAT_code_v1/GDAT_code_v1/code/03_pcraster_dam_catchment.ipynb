{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dam Catchment Shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pcraster as pcr\n",
    "import gdal, gdalconst\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import shape\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/AliceZhang/Dropbox/Research_Columbia/1_Data_Collection/GlobalDam/Analysis/codePython'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# dataDir = os.path.join(r'/scratch/gpfs/tianboz/GlobalDams/Data')\n",
    "dataDir = os.path.join(r'/Users/AliceZhang/Dropbox/Research_Columbia/Zhang_Gu_Conflict_Dam/Data/Raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get shapefile geographic extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dataDir)\n",
    "gdat_af = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_Africa.shp\")\n",
    "gdat_na = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_NorthAmerica.shp\")\n",
    "gdat_sa = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_SouthAmerica.shp\")\n",
    "gdat_as_eu_au = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.shp\")\n",
    "gdat_world = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_World.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabulation of GDAT observations in AF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>5778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      count\n",
       "Continent       \n",
       "Africa      5778\n",
       "Europe        18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabulation of GDAT observations in NA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North America</th>\n",
       "      <td>8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceania</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South America</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          count\n",
       "Continent           \n",
       "North America   8006\n",
       "Oceania            1\n",
       "South America      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabulation of GDAT observations in SA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>South America</th>\n",
       "      <td>5729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          count\n",
       "Continent           \n",
       "South America   5729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabulation of GDAT observations in AS+EU+AU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asia</th>\n",
       "      <td>8776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceania</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South America</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          count\n",
       "Continent           \n",
       "Asia            8776\n",
       "Europe          3116\n",
       "Oceania          266\n",
       "South America      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tabulation of GDAT observations in AF\")\n",
    "pd.crosstab(gdat_af['Continent'], columns='count')\n",
    "\n",
    "print(\"Tabulation of GDAT observations in NA\")\n",
    "pd.crosstab(gdat_na['Continent'], columns='count')\n",
    "\n",
    "print(\"Tabulation of GDAT observations in SA\")\n",
    "pd.crosstab(gdat_sa['Continent'], columns='count')\n",
    "\n",
    "print(\"Tabulation of GDAT observations in AS+EU+AU\")\n",
    "pd.crosstab(gdat_as_eu_au['Continent'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary for AF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-25.16517   , -34.67361111,  49.25      ,  37.23958333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary for NA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-162.873355  ,    8.44283333,  -52.7123    ,   68.073355  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary for SA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-80.84525591, -43.70208333, -34.80208333,  11.34375   ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary for AS+EU+AU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-60.93625   , -45.8816    , 177.37291667,  70.38541667])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary for GDAT global\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-162.873355  ,  -45.8816    ,  177.37291667,   70.38541667])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference extent: http://www.fao.org/geonetwork/srv/en/metadata.show?id=37341\n",
    "\n",
    "print(\"Boundary for AF\")\n",
    "gdat_af.total_bounds\n",
    "# Boundary for Africa: -25.16517, -34.67361111, 51.10000, 38.20000 \n",
    "\n",
    "print(\"Boundary for NA\")\n",
    "gdat_na.total_bounds\n",
    "# Boundary for North America: -162.873355, 8.44283333, -52.7123, 68.073355\n",
    "\n",
    "print(\"Boundary for SA\")\n",
    "gdat_sa.total_bounds\n",
    "# Boundary for South America: -80.84525591, -43.70208333, -34.80208333, 11.34375\n",
    "\n",
    "print(\"Boundary for AS+EU+AU\")\n",
    "gdat_as_eu_au.total_bounds\n",
    "# Boundary for Asia + Europe + Australia: -60.93625, -45.8816, 177.37291667, 70.38541667\n",
    "\n",
    "print(\"Boundary for GDAT global\")\n",
    "gdat_world.total_bounds\n",
    "# Boundary for GDAT global: -162.873355, -45.8816, 177.37291667, 70.38541667\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PCRaster to extract dam catchment area\n",
    "\n",
    "### Step 0\n",
    "- PCRaster reference: http://karssenberg.geo.uu.nl/labs/dataProcessingDem.html\n",
    "\n",
    "- Convert dam .shp file into raster .tif file in shell\n",
    "\n",
    "    - Directory\n",
    "\n",
    "    `cd /scratch/gpfs/tianboz/GlobalDams/Data/CorrectCoord_GDAT_HydroRivers`\n",
    "    \n",
    "    - Use the value \"1\" for all dams\n",
    "    \n",
    "     `gdal_rasterize -l GRanD_dams_v1_1 -burn 1 -tr 0.0174 0.0174 GRanD_dams_v1_1.shp GRanD_dams_v1_1.tif`\n",
    "    \n",
    "    - Use featureID as the value for each dam\n",
    "    \n",
    "    `gdal_rasterize -l GlobalDam_v0_abbVarName -a Feature_ID -tr 0.0174 0.0174 GlobalDam_v0_abbVarName.shp GlobalDam_v0_abbVarName.tif`\n",
    "    \n",
    "    `gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_Africa -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_Africa.shp CorrectCoord_GDAT_HydroRivers_Africa.tif`\n",
    "    \n",
    "    `gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_NorthAmerica -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_NorthAmerica.shp CorrectCoord_GDAT_HydroRivers_NorthAmerica.tif`\n",
    "    \n",
    "    `gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_SouthAmerica -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_SouthAmerica.shp CorrectCoord_GDAT_HydroRivers_SouthAmerica.tif`\n",
    "    \n",
    "    `gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.shp CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.tif`\n",
    "    \n",
    "    `gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_World -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_World.shp CorrectCoord_GDAT_HydroRivers_World.tif`\n",
    "    \n",
    "    \n",
    "- Convert .tif file into PCRaster .map file in shell\n",
    "    \n",
    "    `gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_Africa.tif CorrectCoord_GDAT_HydroRivers_Africa.map`\n",
    "    \n",
    "     `gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_NorthAmerica.tif CorrectCoord_GDAT_HydroRivers_NorthAmerica.map`\n",
    "     \n",
    "     `gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_SouthAmerica.tif CorrectCoord_GDAT_HydroRivers_SouthAmerica.map`\n",
    "      \n",
    "     `gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.tif CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.map`\n",
    "   \n",
    "     `gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_World.tif CorrectCoord_GDAT_HydroRivers_World.map`\n",
    "   \n",
    "   \n",
    "- Find the GDAT file size in pixels and lines\n",
    "\n",
    "    `gdalinfo CorrectCoord_GDAT_HydroRivers_Africa.tif`\n",
    "    \n",
    "    `gdalinfo CorrectCoord_GDAT_HydroRivers_NorthAmerica.tif`\n",
    "    \n",
    "    `gdalinfo CorrectCoord_GDAT_HydroRivers_SouthAmerica.tif`\n",
    "    \n",
    "    `gdalinfo CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.tif`\n",
    "    \n",
    "    `gdalinfo CorrectCoord_GDAT_HydroRivers_World.tif`\n",
    "    \n",
    "    \n",
    "- Clip DEM .bil file to GDAT .shp file extent\n",
    "\n",
    "    `cd /scratch/gpfs/tianboz/GlobalDams/Data/Elevation/HydroSHEDS/DEM_30s_BIL`\n",
    "    \n",
    "    `gdalwarp -te -25.16517 -34.67361111 49.250000 37.23958333 -ts 4265 4121 af_dem_30s_bil/af_dem_30s.bil af_dem_30s_bil/af_dem_30s_subset_gdat.bil`\n",
    "        \n",
    "    `gdalwarp -te -162.873355 8.44283333 -52.7123 68.073355 -ts 6313 3418 na_ca_dem_30s_bil/na_ca_dem_30s.bil na_ca_dem_30s_bil/na_ca_dem_30s_subset_gdat.bil`\n",
    "    \n",
    "    `gdalwarp -te -80.84525591 -43.70208333 -34.80208333 11.34375 -ts 2639 3155 sa_dem_30s_bil/sa_dem_30s.bil sa_dem_30s_bil/sa_dem_30s_subset_gdat.bil`\n",
    "\n",
    "    `cd /scratch/gpfs/tianboz/GlobalDams/Data/Elevation/GMTED2010`\n",
    "    \n",
    "    `gdalwarp -te -60.93625 -45.8816 177.37291667 70.38541667 -ts 13655 6663 as_eu_au_dem_30s_bil/as_eu_au_dem_30s.bil as_eu_au_dem_30s_bil/as_eu_au_dem_30s_subset_gdat.bil`\n",
    "\n",
    "    `gdalwarp -te -162.873355 -45.8816 177.37291667 70.38541667 -ts 19496 6663 mn75_grd/mn75.tif mn75_grd/mn75_subset_gdat.tif`\n",
    "    \n",
    "    \n",
    "- Convert DEM .bil file into PCRaster .map file in shell\n",
    "\n",
    "    `gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR af_dem_30s_bil/af_dem_30s_subset_gdat.bil af_dem_30s_bil/af_dem_30s_subset_gdat.map`\n",
    "    \n",
    "    `gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR na_ca_dem_30s_bil/na_ca_dem_30s_subset_gdat.bil na_ca_dem_30s_bil/na_ca_dem_30s_subset_gdat.map`\n",
    "    \n",
    "    `gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR sa_dem_30s_bil/sa_dem_30s_subset_gdat.bil sa_dem_30s_bil/sa_dem_30s_subset_gdat.map`\n",
    "    \n",
    "    `gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR as_eu_au_dem_30s_bil/as_eu_au_dem_30s_subset_gdat.bil as_eu_au_dem_30s_bil/as_eu_au_dem_30s_subset_gdat.map`\n",
    "    \n",
    "    `gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR mn75_grd/mn75_subset_gdat.tif mn75_grd/mn75_subset_gdat.map`\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DEM files to match GDAT continents\n",
    "\n",
    "cd /scratch/gpfs/tianboz/GlobalDams/Data/Elevation/HydroSHEDS/DEM_30s_BIL/\n",
    "\n",
    "gdal_merge.py -o as_eu_au_dem_30s.bil as_dem_30s_bil/as_dem_30s.bil eu_dem_30s_bil/eu_dem_30s.bil au_dem_30s_bil/au_dem_30s.bil \n",
    "\n",
    "gdal_merge.py -o na_ca_dem_30s.bil na_dem_30s_bil/na_dem_30s.bil ca_dem_30s_bil/ca_dem_30s.bil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert file formats\n",
    "\n",
    "cd /scratch/gpfs/tianboz/GlobalDams/Data/CorrectCoord_GDAT_HydroRivers\n",
    "\n",
    "gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_Africa -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_Africa.shp CorrectCoord_GDAT_HydroRivers_Africa.tif\n",
    "\n",
    "gdal_rasterize -l CorrectCoord_GDAT_HydroRivers_North -a Feature_ID -tr 0.0174532925199433 0.0174532925199433 CorrectCoord_GDAT_HydroRivers_Africa.shp CorrectCoord_GDAT_HydroRivers_Africa.tif\n",
    "\n",
    "\n",
    "\n",
    "gdal_translate -ot Int32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR CorrectCoord_GDAT_HydroRivers_Africa.tif CorrectCoord_GDAT_HydroRivers_Africa.map\n",
    "\n",
    "cd /scratch/gpfs/tianboz/GlobalDams/Data/Elevation/HydroSHEDS/DEM_30s_BIL/\n",
    "\n",
    "gdalwarp -te -25.16517 -34.67361111 49.250000 37.23958333 -ts 4265 4121 af_dem_30s_bil/af_dem_30s.bil af_dem_30s_bil/af_dem_30s_subset_gdat.bil -overwrite\n",
    "\n",
    "gdal_translate -ot Float32 -of PCRaster -mo PCRASTER_VALUESCALE=VS_SCALAR af_dem_30s_bil/af_dem_30s_subset_gdat.bil af_dem_30s_bil/af_dem_30s_subset_gdat.map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "- Load and plot DEM file\n",
    "\n",
    "### Step 2\n",
    "- Calculate Local Drainage Direction (LDD), which indicates the direction of flow of material (e.g. water or sediment) from one cell to its immediate steepest down slope neighboring cell, using the PCRaster lddcreate operator.\n",
    "\n",
    "### Step 3\n",
    "- Verify and relocate to make sure that dams snap to the correct river network\n",
    "\n",
    "### Step 4\n",
    "- Calculate upstream catchment area of dams using PCRaster operator subcatchment\n",
    "    (need to make sure dam location raster has the same number of cells as the elevation raster; same spatial extent)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Calculate Local Drainage Direction (LDD)\n",
      "Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\n"
     ]
    }
   ],
   "source": [
    "# World\n",
    "os.chdir(os.path.join(dataDir, \"Elevation/GMTED2010/mn75_grd/\"))\n",
    "pcr.setclone(\"mn75_subset_gdat.map\") \n",
    "\n",
    "print(\"Step: Calculate Local Drainage Direction (LDD)\")\n",
    "world_ldd = pcr.lddcreate(\"mn75_subset_gdat.map\", 1e31, 1e31, 1e31, 1e31)\n",
    "pcr.report(world_ldd, \"world_ldd.map\")\n",
    "\n",
    "print(\"Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\")\n",
    "os.chdir(os.path.join(dataDir,\"CorrectCoord_GDAT_HydroRivers\"))\n",
    "pcr.setclone(\"CorrectCoord_GDAT_HydroRivers_World.map\") \n",
    "gdat_world = pcr.readmap(\"CorrectCoord_GDAT_HydroRivers_World.map\")\n",
    "\n",
    "gdat_catchment_world = pcr.subcatchment(world_ldd, gdat_world)\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "pcr.report(gdat_catchment_world, \"GDAT_Catchment_World.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(dataDir, \"Elevation/GMTED2010/mn75_grd/\"))\n",
    "pcr.setclone(\"mn75_subset_gdat.map\") \n",
    "pcr.aguila(\"mn75_subset_gdat.map\",\"world_ldd.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Load DEM file\n",
      "Step: Calculate Local Drainage Direction (LDD)\n",
      "Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\n"
     ]
    }
   ],
   "source": [
    "# Africa\n",
    "os.chdir(os.path.join(dataDir, \"Elevation/HydroSHEDS/DEM_30s_BIL/af_dem_30s_bil/\"))\n",
    "pcr.setclone(\"af_dem_30s_subset_gdat.map\") \n",
    "\n",
    "print(\"Step: Load DEM file\")\n",
    "af_dem = pcr.readmap(\"af_dem_30s_subset_gdat.map\")\n",
    "\n",
    "print(\"Step: Calculate Local Drainage Direction (LDD)\")\n",
    "af_ldd = pcr.lddcreate(\"af_dem_30s_subset_gdat.map\", 1e31, 1e31, 1e31, 1e31)\n",
    "pcr.report(af_ldd, \"af_ldd.map\")\n",
    "\n",
    "print(\"Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\")\n",
    "os.chdir(os.path.join(dataDir,\"CorrectCoord_GDAT_HydroRivers\"))\n",
    "pcr.setclone(\"CorrectCoord_GDAT_HydroRivers_Africa.map\") \n",
    "gdat_af = pcr.readmap(\"CorrectCoord_GDAT_HydroRivers_Africa.map\")\n",
    "\n",
    "gdat_catchment_af = pcr.subcatchment(af_ldd, gdat_af)\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "pcr.report(gdat_catchment_af, \"GDAT_Catchment_Africa.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# North America\n",
    "os.chdir(os.path.join(dataDir, \"Elevation/HydroSHEDS/DEM_30s_BIL/na_ca_dem_30s_bil/\"))\n",
    "pcr.setclone(\"na_ca_dem_30s_subset_gdat.map\") \n",
    "\n",
    "print(\"Step: Load DEM file\")\n",
    "na_dem = pcr.readmap(\"na_ca_dem_30s_subset_gdat.map\")\n",
    "\n",
    "print(\"Step: Calculate Local Drainage Direction (LDD)\")\n",
    "na_ldd = pcr.lddcreate(\"na_ca_dem_30s_subset_gdat.map\", 1e31, 1e31, 1e31, 1e31)\n",
    "pcr.report(na_ldd, \"na_ca_ldd.map\")\n",
    "\n",
    "print(\"Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\")\n",
    "os.chdir(os.path.join(dataDir,\"CorrectCoord_GDAT_HydroRivers\"))\n",
    "pcr.setclone(\"CorrectCoord_GDAT_HydroRivers_NorthAmerica.map\") \n",
    "gdat_na = pcr.readmap(\"CorrectCoord_GDAT_HydroRivers_NorthAmerica.map\")\n",
    "\n",
    "gdat_catchment_na = pcr.subcatchment(na_ldd, gdat_na)\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "pcr.report(gdat_catchment_na, \"GDAT_Catchment_NorthAmerica.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# South America\n",
    "os.chdir(os.path.join(dataDir, \"Elevation/HydroSHEDS/DEM_30s_BIL/sa_dem_30s_bil/\"))\n",
    "pcr.setclone(\"sa_dem_30s_subset_gdat.map\") \n",
    "\n",
    "print(\"Step: Load DEM file\")\n",
    "sa_dem = pcr.readmap(\"sa_dem_30s_subset_gdat.map\")\n",
    "\n",
    "print(\"Step: Calculate Local Drainage Direction (LDD)\")\n",
    "sa_ldd = pcr.lddcreate(\"sa_dem_30s_subset_gdat.map\", 1e31, 1e31, 1e31, 1e31)\n",
    "pcr.report(sa_ldd, \"sa_ldd.map\")\n",
    "\n",
    "print(\"Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\")\n",
    "os.chdir(os.path.join(dataDir,\"CorrectCoord_GDAT_HydroRivers\"))\n",
    "pcr.setclone(\"CorrectCoord_GDAT_HydroRivers_SouthAmerica.map\") \n",
    "gdat_sa = pcr.readmap(\"CorrectCoord_GDAT_HydroRivers_SouthAmerica.map\")\n",
    "\n",
    "gdat_catchment_sa = pcr.subcatchment(sa_ldd, gdat_sa)\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "pcr.report(gdat_catchment_sa, \"GDAT_Catchment_SouthAmerica.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asia + Europe + Oceania\n",
    "os.chdir(os.path.join(dataDir, \"Elevation/HydroSHEDS/DEM_30s_BIL/as_eu_au_dem_30s_bil/\"))\n",
    "pcr.setclone(\"as_eu_au_dem_30s_subset_gdat.map\") \n",
    "\n",
    "print(\"Step: Load DEM file\")\n",
    "as_eu_au_dem = pcr.readmap(\"as_eu_au_dem_30s_subset_gdat.map\")\n",
    "\n",
    "print(\"Step: Calculate Local Drainage Direction (LDD)\")\n",
    "as_eu_au_ldd = pcr.lddcreate(\"as_eu_au_dem_30s_subset_gdat.map\", 1e31, 1e31, 1e31, 1e31)\n",
    "pcr.report(as_eu_au_ldd, \"as_eu_au_ldd.map\")\n",
    "\n",
    "print(\"Step: Calculate upstream catchment area of dams using PCRaster operator subcatchment\")\n",
    "os.chdir(os.path.join(dataDir,\"CorrectCoord_GDAT_HydroRivers\"))\n",
    "pcr.setclone(\"CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.map\") \n",
    "gdat_as_eu_au = pcr.readmap(\"CorrectCoord_GDAT_HydroRivers_AsiaOceaniaEurope.map\")\n",
    "\n",
    "gdat_catchment_as_eu_au = pcr.subcatchment(as_eu_au_ldd, gdat_as_eu_au)\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "pcr.report(gdat_catchment_as_eu_au, \"GDAT_Catchment_AsiaOceaniaEurope.map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "- Convert output to shapefile in shell\n",
    "\n",
    "    `cd /scratch/gpfs/tianboz/GlobalDams/Data/PCRaster_Catchment`\n",
    "    \n",
    "    `gdal_translate GDAT_Catchment_Africa.map GDAT_Catchment_Africa.tif`\n",
    "    \n",
    "    `gdal_polygonize.py GDAT_Catchment_Africa.tif GDAT_Catchment_Africa.shp`\n",
    "    \n",
    "    `gdal_translate GDAT_Catchment_NorthAmerica.map GDAT_Catchment_NorthAmerica.tif`\n",
    "    \n",
    "    `gdal_polygonize.py GDAT_Catchment_NorthAmerica.tif GDAT_Catchment_NorthAmerica.shp`\n",
    "\n",
    "    `gdal_translate GDAT_Catchment_SouthAmerica.map GDAT_Catchment_SouthAmerica.tif`\n",
    "    \n",
    "    `gdal_polygonize.py GDAT_Catchment_SouthAmerica.tif GDAT_Catchment_SouthAmerica.shp`\n",
    "\n",
    "    `gdal_translate GDAT_Catchment_AsiaOceaniaEurope.map GDAT_Catchment_AsiaOceaniaEurope.tif`\n",
    "    \n",
    "    `gdal_polygonize.py GDAT_Catchment_AsiaOceaniaEurope.tif GDAT_Catchment_AsiaOceaniaEurope.shp`\n",
    "    \n",
    "    `gdal_translate GDAT_Catchment_World.map GDAT_Catchment_World.tif` \n",
    "    \n",
    "    `gdal_polygonize.py GDAT_Catchment_World.tif GDAT_Catchment_World.shp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Merge catchment with GDAT dam layer to get attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine continent-specific catchment shapefiles\n",
    "# os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "# catchment_af = gpd.read_file(\"GDAT_Catchment_Africa.shp\")\n",
    "# catchment_na = gpd.read_file(\"GDAT_Catchment_NorthAmerica.shp\")\n",
    "# catchment_sa = gpd.read_file(\"GDAT_Catchment_SouthAmerica.shp\")\n",
    "# catchment_as_eu_au = gpd.read_file(\"GDAT_Catchment_AsiaOceaniaEurope.shp\")\n",
    "# catchment_world = catchment_af.append(catchment_na).append(catchment_sa).append(catchment_as_eu_au)\n",
    "# catchment_world.to_file(\"GDAT_Catchment_HydroSHEDS_World.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import catchment \n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "catchment_world = gpd.read_file(\"GDAT_Catchment_World.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DN</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-160.82259 70.39414, -160.80514 70.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-151.41527 70.39414, -151.39782 70.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-128.21984 70.39414, -128.20239 70.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-128.18494 70.39414, -128.09767 70.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-92.03917 70.39414, -92.02171 70.394...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DN                                           geometry\n",
       "0   0  POLYGON ((-160.82259 70.39414, -160.80514 70.3...\n",
       "1   0  POLYGON ((-151.41527 70.39414, -151.39782 70.3...\n",
       "2   0  POLYGON ((-128.21984 70.39414, -128.20239 70.3...\n",
       "3   0  POLYGON ((-128.18494 70.39414, -128.09767 70.3...\n",
       "4   0  POLYGON ((-92.03917 70.39414, -92.02171 70.394..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0        18872\n",
       "6046        17\n",
       "23048       11\n",
       "20737        8\n",
       "2562         6\n",
       "         ...  \n",
       "2004         1\n",
       "6102         1\n",
       "8151         1\n",
       "20445        1\n",
       "18457        1\n",
       "Name: DN, Length: 28461, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_ID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33769</td>\n",
       "      <td>POLYGON ((26.92247 70.39414, 27.00974 70.39414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31950</td>\n",
       "      <td>POLYGON ((26.80030 70.37669, 26.83521 70.37669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>32901</td>\n",
       "      <td>POLYGON ((29.08668 70.02762, 29.12159 70.02762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>33568</td>\n",
       "      <td>POLYGON ((21.77375 69.71346, 21.79121 69.71346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>35033</td>\n",
       "      <td>POLYGON ((23.65871 69.69601, 23.67616 69.69601...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_ID                                           geometry\n",
       "8         33769  POLYGON ((26.92247 70.39414, 27.00974 70.39414...\n",
       "19        31950  POLYGON ((26.80030 70.37669, 26.83521 70.37669...\n",
       "202       32901  POLYGON ((29.08668 70.02762, 29.12159 70.02762...\n",
       "306       33568  POLYGON ((21.77375 69.71346, 21.79121 69.71346...\n",
       "317       35033  POLYGON ((23.65871 69.69601, 23.67616 69.69601..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6046     17\n",
       "23048    11\n",
       "20737     8\n",
       "2159      6\n",
       "2562      6\n",
       "         ..\n",
       "2004      1\n",
       "6102      1\n",
       "8151      1\n",
       "20445     1\n",
       "4098      1\n",
       "Name: Feature_ID, Length: 28460, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 0 DN values \n",
    "catchment_world.head()\n",
    "catchment_world['DN'].value_counts()\n",
    "catchment_world_rmDN = catchment_world[catchment_world.DN != 0]\n",
    "catchment_world_rmDN.rename(columns = {'DN':'Feature_ID'}, inplace = True)\n",
    "catchment_world_rmDN.head()\n",
    "catchment_world_rmDN['Feature_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve polygons with the same FeatureID\n",
    "catchment_world_rmDN = catchment_world_rmDN.dissolve(by='Feature_ID', aggfunc = 'first').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save global dam catchment shapefile with DN = 0 removed and polygons dissolved\n",
    "os.chdir(os.path.join(dataDir, \"PCRaster_Catchment\"))\n",
    "catchment_world_rmDN.to_file(\"GDAT_Catchment_World_Cleaned.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load GDAT world data\n",
    "os.chdir(dataDir)\n",
    "gdat_world = gpd.read_file(\"CorrectCoord_GDAT_HydroRivers/CorrectCoord_GDAT_HydroRivers_World.shp\")\n",
    "\n",
    "# Replace geometry as string\n",
    "gdat_world['geometry'] = gdat_world['geometry'].apply(lambda x: wkt.dumps(x))\n",
    "gdat_world.rename(columns = {'geometry': 'Correct_Coord'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge catchment with GDAT file for attributes\n",
    "gdat_catchment_world = gdat_world.merge(catchment_world_rmDN, on = 'Feature_ID', how='outer', validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged GDAT & catchment data\n",
    "os.chdir(dataDir)\n",
    "gdat_catchment_world.to_file(\"PCRaster_Catchment/GDAT_Catchment_World_Merged.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Useful Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .bil file \n",
    "def readbil(bil):\n",
    "    gdal.GetDriverByName('EHdr').Register()\n",
    "    img = gdal.Open(bil)\n",
    "    band = img.GetRasterBand(1)\n",
    "    data = band.ReadAsArray()\n",
    "    return data\n",
    "af = readbil(os.path.join(dataDir, \"Raw/Elevation/HydroSHEDS/DEM_15s_BIL/af_dem_15s_bil\", \"af_dem_15s.bil\"))\n",
    "af.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr.aguila?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcraster37",
   "language": "python",
   "name": "pcraster37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
